{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "import utils.get_data as data\n",
    "import utils.plots as plots\n",
    "\n",
    "from IPython.display import Image, display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1234)\n",
    "root = '/Users/kdgutier/Desktop/cov_shift/'\n",
    "\n",
    "n_clusters = 6\n",
    "X, Y, V = data.load_data_experiment(n_clusters, path=(root + 'data/'))\n",
    "plots.graph_data_experiment(n_clusters, X, Y, V, path=(root+'images/experiment2.png') )\n",
    "\n",
    "datos = data.split_data_experiment(n_clusters, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_vall(n_clusters, objective_c, propscores):\n",
    "    proxy_clusters = [objective_c, objective_c + n_clusters]\n",
    "    objective = propscores[:, proxy_clusters]\n",
    "    objective = np.sum(objective, axis=1)\n",
    "    complement = np.delete(propscores, proxy_clusters, axis=1)\n",
    "    complement = np.sum(complement, axis=1)\n",
    "    objective_vall = np.column_stack((objective, complement))\n",
    "    return objective_vall\n",
    "\n",
    "def qda_propscores(n_clusters, df, is_test=False):\n",
    "    # data\n",
    "    X_propscore, y_propscore = df['X_propscore'], df['y_propscore']\n",
    "    X_train, y_train = df['X_train'], df['y_train']\n",
    "    X_test, y_test = df['X_test'], df['y_test']\n",
    "    # lda for the propscore training\n",
    "    X_ps, y_ps, proxy_clusters = data.parse_data_propscore(n_clusters, X_propscore, y_propscore)\n",
    "    model = QuadraticDiscriminantAnalysis(reg_param=0.0).fit(X_ps, proxy_clusters)\n",
    "    # lda propscores for actual training\n",
    "\n",
    "    # inference\n",
    "    if is_test==True:\n",
    "        X_test_ps, _ , _ = data.parse_data_propscore(n_clusters, X_test, y_test)\n",
    "        propscores = model.predict_proba(X_test_ps)\n",
    "    else:\n",
    "        X_train_ps, _ , _ = data.parse_data_propscore(n_clusters, X_train, y_train)\n",
    "        propscores = model.predict_proba(X_train_ps)\n",
    "    \n",
    "    return propscores\n",
    "\n",
    "def correct_propscores(n_clusters, propscores):\n",
    "    correct_propscores = np.zeros(shape=(propscores.shape[0], n_clusters))\n",
    "    for c in range(n_clusters):\n",
    "        correct_propscores[:, c] = propscores[:, c] + propscores[:, (c + n_clusters)]\n",
    "    return correct_propscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=6\n",
    "propscores = qda_propscores(n_clusters, datos)\n",
    "plots.graph_first_stage(n_clusters, df=datos, V=V, propscores=propscores, path=(root+'images/experiment_1stage.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_logistic(n_clusters, df):\n",
    "    X_train, y_train, _ = data.parse_data(n_clusters, df['X_train'], df['y_train'])\n",
    "    X_test, y_test, _ = data.parse_data(n_clusters, df['X_test'], df['y_test'])\n",
    "    # model\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    # inference\n",
    "    y_hat = model.predict(X_test)\n",
    "    return y_hat\n",
    "\n",
    "def weighted_logistic(n_clusters, df, weights):\n",
    "    X_train, y_train, _ = data.parse_data(n_clusters, df['X_train'], df['y_train'])\n",
    "    X_test, y_test, _ = data.parse_data(n_clusters, df['X_test'], df['y_test'])\n",
    "    # model\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(X_train, y_train, sample_weight=weights)\n",
    "    # inference\n",
    "    y_hat = model.predict(X_test)\n",
    "    return y_hat\n",
    "\n",
    "def pure_logistic(n_clusters, df):\n",
    "    X_train, y_train, clusters_train = data.parse_data(n_clusters, df['X_train'], df['y_train'])\n",
    "    X_test, y_test, clusters_test = data.parse_data(n_clusters, df['X_test'], df['y_test'])\n",
    "    \n",
    "    y_hat = np.zeros(shape=(X_test.shape[0],))\n",
    "    for c in range(n_clusters):\n",
    "        X_train_c, y_train_c = X_train[clusters_train == c], y_train[clusters_train == c]\n",
    "        X_test_c, y_test_c = X_test[clusters_test == c], y_test[clusters_test == c]\n",
    "        model = linear_model.LogisticRegression()\n",
    "        model.fit(X_train_c, y_train_c)\n",
    "        y_hat_c = model.predict(X_test_c)\n",
    "        y_hat[clusters_test == c] = y_hat_c\n",
    "    return y_hat\n",
    "\n",
    "def dm_logistic(n_clusters, df):\n",
    "    X_train, y_train, clusters_train = data.parse_data(n_clusters, df['X_train'], df['y_train'])\n",
    "    X_test, y_test, clusters_test = data.parse_data(n_clusters, df['X_test'], df['y_test'])\n",
    "    \n",
    "    # Train\n",
    "    propscores = qda_propscores(n_clusters, df)\n",
    "    y_hat_models = np.zeros(shape=(X_test.shape[0], n_clusters))\n",
    "    y_hat = np.zeros(shape=X_test.shape[0])\n",
    "    for c in range(n_clusters):\n",
    "        prop_weights = objective_vall(n_clusters, c, propscores)[:,0]\n",
    "        model = linear_model.LogisticRegression()\n",
    "        model.fit(X_train, y_train, sample_weight=prop_weights)\n",
    "        y_hat_c = model.predict(X_test)\n",
    "        y_hat_models[:,c] = y_hat_c\n",
    "    \n",
    "    # Test\n",
    "    propscores = qda_propscores(n_clusters, df, is_test=True)\n",
    "    propscores = correct_propscores(n_clusters, propscores)\n",
    "    model_selector = np.argmax(propscores, axis=1)\n",
    "    for idx in range(X_test.shape[0]):\n",
    "        y_hat[idx] = y_hat_models[idx, model_selector[idx]-1]\n",
    "    return y_hat\n",
    "\n",
    "def svm_benchmark(df):\n",
    "    pass\n",
    "\n",
    "def goodness_fit(y_hat, y):\n",
    "    n_test = y.shape[0]\n",
    "    true_p = np.sum(np.multiply(1*(y_hat==1), 1*(y==1)))\n",
    "    false_p = np.sum(np.multiply(y_hat==1,y==0))\n",
    "    true_n = np.sum(np.multiply(y_hat==0,y==0))\n",
    "    false_n = np.sum(np.multiply(y_hat==0,y==1))\n",
    "    \n",
    "    assert (true_p + false_p + true_n + false_n) == n_test\n",
    "    precision = true_p // (true_p+false_p)\n",
    "    recall = true_p // (true_p+false_n)\n",
    "    accuracy = (true_p + true_n) // n_test\n",
    "    \n",
    "    print(precision); print(recall); print(accuracy)\n",
    "    \n",
    "    return precision, recall, accuracy\n",
    "\n",
    "def compare_models(n_clusters, df):\n",
    "    _, y_test, _ = data.parse_data(n_clusters, df['X_test'], df['y_test'])\n",
    "    \n",
    "    y_hat_naive = naive_logistic(n_clusters, df)\n",
    "    y_hat_pure = pure_logistic(n_clusters, df)\n",
    "    y_hat_dm = dm_logistic(n_clusters, df)\n",
    "    \n",
    "    #table = np.zeros(shape=(3,3))\n",
    "    t1 = goodness_fit(y_hat_naive, y_test)\n",
    "    t2 = goodness_fit(y_hat_naive, y_test)\n",
    "    t3 = goodness_fit(y_hat_naive, y_test)\n",
    "    table = np.vstack((t1,t2,t3))\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#ver = weighted_logistic(n_clusters, datos, weights=prop_weights)\n",
    "#ver = naive_logistic(n_clusters, datos)\n",
    "#ver = pure_logistic(n_clusters, datos)\n",
    "#ver = dm_logistic(n_clusters, datos)\n",
    "ver = compare_models(n_clusters, datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "        0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,\n",
       "        1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,\n",
       "        0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
